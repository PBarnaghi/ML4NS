{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            src: Tensor, shape ``[seq_len, batch_size]``\n",
    "            src_mask: Tensor, shape ``[seq_len, seq_len]``\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape ``[seq_len, batch_size, ntoken]``\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
    "    \"\"\"Generates an upper-triangular matrix of ``-inf``, with zeros on ``diag``.\"\"\"\n",
    "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import WikiText2\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "train_iter = WikiText2(split='train')\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
    "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
    "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
    "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
    "\n",
    "# ``train_iter`` was \"consumed\" by the process of building the vocab,\n",
    "# so we have to create it again\n",
    "train_iter, val_iter, test_iter = WikiText2()\n",
    "train_data = data_process(train_iter)\n",
    "val_data = data_process(val_iter)\n",
    "test_data = data_process(test_iter)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
    "    \"\"\"Divides the data into ``bsz`` separate sequences, removing extra elements\n",
    "    that wouldn't cleanly fit.\n",
    "\n",
    "    Arguments:\n",
    "        data: Tensor, shape [N]\n",
    "        bsz: int, batch size\n",
    "\n",
    "    Returns:\n",
    "        Tensor of shape ``[N // bsz, bsz]``\n",
    "    \"\"\"\n",
    "    seq_len = data.size(0) // bsz\n",
    "    data = data[:seq_len * bsz]\n",
    "    data = data.view(bsz, seq_len).t().contiguous()\n",
    "    return data.to(device)\n",
    "\n",
    "batch_size = 20\n",
    "eval_batch_size = 10\n",
    "train_data = batchify(train_data, batch_size)  # shape ``[seq_len, batch_size]``\n",
    "val_data = batchify(val_data, eval_batch_size)\n",
    "test_data = batchify(test_data, eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt = 35\n",
    "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        source: Tensor, shape ``[full_seq_len, batch_size]``\n",
    "        i: int\n",
    "\n",
    "    Returns:\n",
    "        tuple (data, target), where data has shape ``[seq_len, batch_size]`` and\n",
    "        target has shape ``[seq_len * batch_size]``\n",
    "    \"\"\"\n",
    "    seq_len = min(bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
    "    return data, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = len(vocab)  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in ``nn.TransformerEncoder``\n",
    "nlayers = 2  # number of ``nn.TransformerEncoderLayer`` in ``nn.TransformerEncoder``\n",
    "nhead = 2  # number of heads in ``nn.MultiheadAttention``\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 200\n",
    "    start_time = time.time()\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "\n",
    "    num_batches = len(train_data) // bptt\n",
    "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
    "        data, targets = get_batch(train_data, i)\n",
    "        seq_len = data.size(0)\n",
    "        if seq_len != bptt:  # only on last batch\n",
    "            src_mask = src_mask[:seq_len, :seq_len]\n",
    "        output = model(data, src_mask)\n",
    "        loss = criterion(output.view(-1, ntokens), targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = math.exp(cur_loss)\n",
    "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
    "            data, targets = get_batch(eval_data, i)\n",
    "            seq_len = data.size(0)\n",
    "            if seq_len != bptt:\n",
    "                src_mask = src_mask[:seq_len, :seq_len]\n",
    "            output = model(data, src_mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
    "    return total_loss / (len(eval_data) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 487.85 | loss  8.23 | ppl  3767.64\n",
      "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 537.05 | loss  6.93 | ppl  1025.23\n",
      "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 650.56 | loss  6.46 | ppl   638.56\n",
      "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 561.33 | loss  6.31 | ppl   551.86\n",
      "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 716.72 | loss  6.19 | ppl   488.95\n",
      "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 706.46 | loss  6.16 | ppl   473.53\n",
      "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 719.46 | loss  6.12 | ppl   453.00\n",
      "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 835.85 | loss  6.11 | ppl   448.48\n",
      "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 795.02 | loss  6.03 | ppl   415.12\n",
      "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 644.65 | loss  6.02 | ppl   411.93\n",
      "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 516.80 | loss  5.91 | ppl   368.09\n",
      "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 467.08 | loss  5.97 | ppl   393.05\n",
      "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 556.20 | loss  5.96 | ppl   385.78\n",
      "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 557.86 | loss  5.89 | ppl   360.52\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time: 1876.13s | valid loss  5.81 | valid ppl   333.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 552.42 | loss  5.87 | ppl   354.20\n",
      "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 551.04 | loss  5.87 | ppl   352.64\n",
      "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 572.53 | loss  5.68 | ppl   291.82\n",
      "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 601.96 | loss  5.70 | ppl   299.80\n",
      "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 554.92 | loss  5.65 | ppl   285.43\n",
      "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 485.10 | loss  5.68 | ppl   293.32\n",
      "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 471.29 | loss  5.69 | ppl   296.65\n",
      "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 2859.87 | loss  5.71 | ppl   302.36\n",
      "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 427.57 | loss  5.65 | ppl   283.70\n",
      "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 479.95 | loss  5.66 | ppl   286.93\n",
      "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 543.47 | loss  5.55 | ppl   256.99\n",
      "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 493.55 | loss  5.64 | ppl   282.51\n",
      "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 477.35 | loss  5.64 | ppl   282.65\n",
      "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 489.76 | loss  5.58 | ppl   264.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time: 2072.88s | valid loss  5.64 | valid ppl   280.60\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 568.33 | loss  5.60 | ppl   269.99\n",
      "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 492.51 | loss  5.62 | ppl   276.45\n",
      "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 500.99 | loss  5.42 | ppl   226.50\n",
      "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 499.28 | loss  5.48 | ppl   240.44\n",
      "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 588.13 | loss  5.44 | ppl   231.41\n",
      "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 576.22 | loss  5.47 | ppl   238.08\n",
      "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 584.82 | loss  5.49 | ppl   241.37\n",
      "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 451.63 | loss  5.51 | ppl   248.00\n",
      "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 505.26 | loss  5.46 | ppl   235.26\n",
      "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 477.59 | loss  5.48 | ppl   239.67\n",
      "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 485.69 | loss  5.35 | ppl   209.61\n",
      "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 494.41 | loss  5.46 | ppl   235.11\n",
      "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 490.68 | loss  5.47 | ppl   236.75\n",
      "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 530.49 | loss  5.40 | ppl   221.12\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time: 1568.43s | valid loss  5.61 | valid ppl   273.91\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 3\n",
    "\n",
    "with TemporaryDirectory() as tempdir:\n",
    "    best_model_params_path = os.path.join(tempdir, \"best_model_params.pt\")\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        train(model)\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        val_ppl = math.exp(val_loss)\n",
    "        elapsed = time.time() - epoch_start_time\n",
    "        print('-' * 89)\n",
    "        print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
    "            f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "        print('-' * 89)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), best_model_params_path)\n",
    "\n",
    "        scheduler.step()\n",
    "    model.load_state_dict(torch.load(best_model_params_path)) # load best model states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========================================================================================\n",
      "| End of training | test loss  5.52 | test ppl   250.57\n",
      "=========================================================================================\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data)\n",
    "test_ppl = math.exp(test_loss)\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
